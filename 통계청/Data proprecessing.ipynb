{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39dacb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from konlpy.tag import Okt\n",
    "import sklearn\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from konlpy.tag import Kkma\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cccd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_table(\"train.txt\", sep=\"|\",encoding = \"cp949\")\n",
    "test = pd.read_table(\"test.txt\",sep=\"|\",encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7082f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(\"\")\n",
    "test = test.fillna(\"\")\n",
    "\n",
    "train['total_text'] = train['text_obj'] + \" \" + train['text_mthd'] + \" \" + train['text_deal']\n",
    "train.head()\n",
    "\n",
    "test['total_text'] = test['text_obj'] + \" \" + test['text_mthd'] + \" \" + test['text_deal']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "656d36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a90277a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_1 = ['은','는','이','가', '에게', '으로',\"의\",'고', '의해', '해', '을','를', '에서', \"로\", \"대상\", \"및\", \"등\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd11876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, okt, remove_stopwords = False, stop_words = []):\n",
    "    # 함수의 인자는 다음과 같다.\n",
    "    # review : 전처리할 텍스트\n",
    "    # okt : okt 객체를 반복적으로 생성하지 않고 미리 생성후 인자로 받는다.\n",
    "    # remove_stopword : 불용어를 제거할지 선택 기본값은 False\n",
    "    # stop_word : 불용어 사전은 사용자가 직접 입력해야함 기본값은 비어있는 리스트\n",
    "    \n",
    "    # 1. 한글 및 공백을 제외한 문자 모두 제거.\n",
    "    #review_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", review)\n",
    "    text = re.sub('\\\\\\\\n', ' ', text)\n",
    "    # 특수문자 제거\n",
    "    # 특수문자나 이모티콘 등은 때로는 의미를 갖기도 하지만 여기에서는 제거했습니다.\n",
    "    text = re.sub('[?.,;:|\\)*~`’!^\\-_+<>@\\#$%&-=#}※]', '', text)\n",
    "    # 한글, 영문, 숫자만 남기고 모두 제거하도록 합니다.\n",
    "    # text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9]', ' ', text)\n",
    "    # 한글, 영문만 남기고 모두 제거하도록 합니다.\n",
    "    text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z]', ' ', text)\n",
    "    # 중복으로 생성된 공백값을 제거합니다.\n",
    "    text = re.sub('[\\s]+', ' ', text)\n",
    "    \n",
    "    # 2. okt 객체를 활용해서 형태소 단위로 나눈다. (형태소분석기 다른거 쓸 때 여기 변경하시면 됩니당!)\n",
    "    word_review = kkma.morphs(text) #, stem=True)\n",
    "    \n",
    "    if remove_stopwords:\n",
    "        \n",
    "        # 불용어 제거(선택적)\n",
    "        word_review = [token for token in word_review if not token in stop_words_1]\n",
    "        \n",
    "   \n",
    "    return word_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d83cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_text = []\n",
    "for i in tqdm(range(len(train['total_text']))):\n",
    "    clean_train_text.append(preprocessing(train['total_text'][i], okt, remove_stopwords = True, stop_words= stop_words_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6ac47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_text = []\n",
    "for i in tqdm(range(len(test['total_text']))):\n",
    "    clean_test_text.append(preprocessing(test['total_text'][i], okt, remove_stopwords = True, stop_words= stop_words_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82465f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장 \n",
    "with open('train_text_kkma_morphs불1.pickle', 'wb') as f:\n",
    "    pickle.dump(clean_train_text, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('test_text_kkma_morphs불1.pickle', 'wb') as f:\n",
    "    pickle.dump(clean_test_text, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lstm(50)2층_kh.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
